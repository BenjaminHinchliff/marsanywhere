@incollection{M2020_Willford2018,
  title = {Chapter 11 - The NASA Mars 2020 Rover Mission and the Search for
           Extraterrestrial Life},
  editor = {Nathalie A. Cabrol and Edmond A. Grin},
  booktitle = {From Habitability to Life on Mars},
  publisher = {Elsevier},
  pages = {275-308},
  year = {2018},
  isbn = {978-0-12-809935-3},
  doi = {https://doi.org/10.1016/B978-0-12-809935-3.00010-4},
  url = {https://www.sciencedirect.com/science/article/pii/B9780128099353000104},
  author = {Kenneth H. Williford and Kenneth A. Farley and Kathryn M. Stack and
            Abigail C. Allwood and David Beaty and Luther W. Beegle and Rohit
            Bhartia and Adrian J. Brown and Manuel {de la Torre Juarez} and
            Svein-Erik Hamran and Michael H. Hecht and Joel A. Hurowitz and Jose
            A. Rodriguez-Manfredi and Sylvestre Maurice and Sarah Milkovich and
            Roger C. Wiens},
  keywords = {Mars 2020, Mars sample return, Astrobiology, Planetary evolution},
  abstract = {The NASA Mars 2020 rover mission will explore an astrobiologically
              relevant martian site to investigate regional geology, evaluate
              past habitability, seek signs of ancient life, and assemble a
              returnable cache of samples. The spacecraft is based on successful
              heritage design of the Mars Science Laboratory Curiosity rover, but
              includes a new scientific payload and other advanced capabilities.
              The Mars 2020 science payload features the first two Raman
              spectrometers on Mars, the first microfocus X-ray fluorescence
              instrument, the first ground-penetrating radar, an infrared
              spectrometer, an upgraded microscopic and stereo context cameras
              and weather station, and a demonstration unit for oxygen production
              on Mars. The instrument suite combines visible and multispectral
              imaging with coordinated measurements of chemistry and mineralogy,
              from the submillimeter to the regional scale. Using the data
              acquired by the science instruments as a guide, the team will
              collect core samples of rock and regolith selected to represent the
              geologic diversity of the landing site and maximize the potential
              for future Earth-based analyses to answer fundamental questions in
              astrobiology and planetary science. These samples will be drilled,
              hermetically sealed, and cached on the martian surface for possible
              retrieval and return to Earth by future missions. The Mars 2020
              spacecraft is designed and built according to an unprecedented set
              of biological, organic, and inorganic cleanliness requirements to
              maximize the scientific value of this sample suite. Here, we
              present the scientific vision for the Mars 2020 mission, provide an
              overview of the analytic capabilities of the science payload, and
              discuss how Mars 2020 seeks to further our understanding of
              habitability, biosignatures, and possibility of life beyond Earth.},
}

@article{MSLNavcam_Maki2012,
  author = {Maki, J. and Thiessen, D. and Pourangi, A. and Kobzeff, P. and
            Litwin, T. and Scherr, L. and Elliott, S. and Dingizian, A. and
            Maimone, M.},
  title = {The Mars Science Laboratory Engineering Cameras},
  journal = {Space\,Science\,Reviews},
  volume = {170},
  pages = {77--93},
  year = {2012},
  doi = {10.1007/s11214-012-9882-4},
}


@article{HiRISE_McEwen2007,
  author = {McEwen, Alfred S. and Eliason, Eric M. and Bergstrom, James W. and
            Bridges, Nathan T. and Hansen, Candice J. and Delamere, W. Alan and
            Grant, John A. and Gulick, Virginia C. and Herkenhoff, Kenneth E. and
            Keszthelyi, Laszlo and Kirk, Randolph L. and Mellon, Michael T. and
            Squyres, Steven W. and Thomas, Nicolas and Weitz, Catherine M.},
  title = {Mars Reconnaissance Orbiter's High Resolution Imaging Science
           Experiment (HiRISE)},
  journal = {Journal of Geophysical Research: Planets},
  volume = {112},
  number = {E5},
  pages = {},
  keywords = {geology, imaging, Mars},
  doi = {https://doi.org/10.1029/2005JE002605},
  url = {https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2005JE002605},
  eprint = {https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1029/2005JE002605
            },
  abstract = {The HiRISE camera features a 0.5 m diameter primary mirror, 12 m
              effective focal length, and a focal plane system that can acquire
              images containing up to 28 Gb (gigabits) of data in as little as 6
              seconds. HiRISE will provide detailed images (0.25 to 1.3 m/pixel)
              covering ∼1\% of the Martian surface during the 2-year Primary
              Science Phase (PSP) beginning November 2006. Most images will
              include color data covering 20\% of the potential field of view. A
              top priority is to acquire ∼1000 stereo pairs and apply precision
              geometric corrections to enable topographic measurements to better
              than 25 cm vertical precision. We expect to return more than 12 Tb
              of HiRISE data during the 2-year PSP, and use pixel binning,
              conversion from 14 to 8 bit values, and a lossless compression
              system to increase coverage. HiRISE images are acquired via 14 CCD
              detectors, each with 2 output channels, and with multiple choices
              for pixel binning and number of Time Delay and Integration lines.
              HiRISE will support Mars exploration by locating and characterizing
              past, present, and future landing sites, unsuccessful landing sites
              , and past and potentially future rover traverses. We will
              investigate cratering, volcanism, tectonism, hydrology, sedimentary
              processes, stratigraphy, aeolian processes, mass wasting, landscape
              evolution, seasonal processes, climate change, spectrophotometry,
              glacial and periglacial processes, polar geology, and regolith
              properties. An Internet Web site (HiWeb) will enable anyone in the
              world to suggest HiRISE targets on Mars and to easily locate, view,
              and download HiRISE data products.},
  year = {2007},
}

@inproceedings{MarsTrek_Law2017,
  author = {Law, Emily and Day, Brian},
  title = {Mars Trek: An Interactive Web Portal for Current and Future Missions
           to Mars},
  booktitle = {EPSC Abstracts, Vol. 11, EPSC2017-99},
  year = {2017},
  organization = {European Planetary Science Congress},
  location = {Riga, Latvia},
  date = {September 17–22, 2017},
  note = {Presented at EPSC 2017},
  url = {https://meetingorganizer.copernicus.org/EPSC2017/EPSC2017-99.pdf},
}


@inproceedings{Diffusion_Ho2020,
  author = {Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  booktitle = {Advances in Neural Information Processing Systems},
  editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H.
            Lin},
  pages = {6840--6851},
  publisher = {Curran Associates, Inc.},
  title = {Denoising Diffusion Probabilistic Models},
  url = {
         https://proceedings.neurips.cc/paper_files/paper/2020/file/4c5bcfec8584af0d967f1ab10179ca4b-Paper.pdf
         },
  volume = {33},
  year = {2020},
}


@inproceedings{LatentDiffusion_Rombach2022,
  author = {Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser,
            Patrick and Ommer, Bj\"orn},
  title = {High-Resolution Image Synthesis With Latent Diffusion Models},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and
               Pattern Recognition (CVPR)},
  month = {June},
  year = {2022},
  pages = {10684-10695},
}

@misc{ControlNet_Zhang2023,
  title = {Adding Conditional Control to Text-to-Image Diffusion Models},
  author = {Lvmin Zhang and Anyi Rao and Maneesh Agrawala},
  year = {2023},
  eprint = {2302.05543},
  archivePrefix = {arXiv},
  primaryClass = {cs.CV},
  url = {https://arxiv.org/abs/2302.05543},
}

@dataset{USGS_Mars2020_TRN_HiRISE_2020,
  author       = {USGS Astrogeology Science Center},
  title        = {Mars 2020 Terrain Relative Navigation HiRISE Orthorectified Image Mosaic},
  institution  = {USGS Astrogeology Science Center},
  year         = {2020},
  month        = {07},
  day          = {24},
  url          = {https://astrogeology.usgs.gov/search/map/mars_2020_terrain_relative_navigation_hirise_orthorectified_image_mosaic},
}



@dataset{PDS_IMG_Node_Mars2020,
  author       = {{NASA PDS Imaging Node, JPL}},
  title        = {Mars 2020 Perseverance Rover ("Perseverance") Image Archive – PDS Imaging Node},
  year         = {2025},
  version      = {Release 13},
  institution  = {NASA Planetary Data System, PDS Imaging Node, Jet Propulsion Laboratory},
  url          = {https://pds-imaging.jpl.nasa.gov/},
}


@dataset{mars2020_spice_kernels_2025,
  title        = {Mars 2020 Perseverance Rover Mission – SPICE Kernel Archive},
  author       = {Costa Sitja, M. and Semenov, B. V. and Barnes, M. J. and Bailey, A. M.},
  year         = {2025},
  url          = {https://naif.jpl.nasa.gov/pub/naif/pds/pds4/mars2020/mars2020_spice/},
  note         = {DOI: 10.17189/1522854; Navigation and Ancillary Information Facility (NAIF), Planetary Data System (PDS) PDS4 archive},
}

@article{SpiceyPy_Annex2020,
  author       = {Annex, A. and Acton, C. and Raugh, A. and Seidelmann, K.},
  title        = {SpiceyPy: a Pythonic Wrapper for the SPICE Toolkit},
  journal      = {Journal of Open Source Software},
  year         = {2020},
  volume       = {5},
  number       = {46},
  pages        = {2050},
  doi          = {10.21105/joss.02050},
  url          = {https://doi.org/10.21105/joss.02050}
}


@software{hinchliff2025rms‐vicar,
  author       = {Robert French and Mark Showalter and Benjamin Hinchliff},
  title        = {rms-vicar: vicar Python module},
  year         = {2025},
  version      = {5ad4cc2},
  url          = {https://github.com/BenjaminHinchliff/rms-vicar},
  note         = {GitHub repository, forked from SETI/rms-vicar},
}

@Manual{GDAL_2025,
  title = {{GDAL/OGR} Geospatial Data Abstraction software Library},
  author = {{GDAL/OGR contributors}},
  organization = {Open Source Geospatial Foundation},
  year = {2025},
  url = {https://gdal.org},
  doi = {10.5281/zenodo.5884351},
}

@Software{VICAR,
    title = {VICAR},
    author = {Bob Deen and PDS},
    year = {2023},
    version = {5.0},
    url = {https://github.com/NASA-AMMOS/VICAR},
    note = {GitHub repository}
}

@misc{li2024crossviewdiff,
      title={CrossViewDiff: A Cross-View Diffusion Model for Satellite-to-Street View Synthesis},
      author={Weijia Li and Jun He and Junyan Ye and Huaping Zhong and Zhimeng Zheng and Zilong Huang and Dahua Lin and Conghui He},
      year={2024},
      eprint={2408.14765},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2408.14765},
}

@Software{blender2025,
   title = {Blender - a 3D modelling and rendering package},
   author = {Blender Online Community},
   organization = {Blender Foundation},
   address = {Stichting Blender Foundation, Amsterdam},
   year = {2025},
   url = {http://www.blender.org},
 }

@INPROCEEDINGS{tang2019selectiongan,
    author={Tang, Hao and Xu, Dan and Sebe, Nicu and Wang, Yanzhi and Corso, Jason J. and Yan, Yan},
    booktitle={2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    title={Multi-Channel Attention Selection GAN With Cascaded Semantic Guidance for Cross-View Image Translation},
    year={2019},
    volume={},
    number={},
    pages={2412-2421},
    keywords={Computer vision;Uncertainty;Translation;Deformation;Source coding;Semantics;Generative adversarial networks;Data models;Pattern recognition;Optimization;Image and Video Synthesis},
    doi={10.1109/CVPR.2019.00252}
}

@InProceedings{zhai2017groundlayout,
author = {Zhai, Menghua and Bessinger, Zachary and Workman, Scott and Jacobs, Nathan},
title = {Predicting Ground-Level Scene Layout From Aerial Imagery},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {July},
year = {2017}
}

@InProceedings{lu2020geometryaware,
author = {Lu, Xiaohu and Li, Zuoyue and Cui, Zhaopeng and Oswald, Martin R. and Pollefeys, Marc and Qin, Rongjun},
title = {Geometry-Aware Satellite-to-Ground Image Synthesis for Urban Areas},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2020}
}

@inproceedings{castaldo2015featurematching,
author = {Castaldo, Francesco and Zamir, Amir and Angst, Roland and Palmieri, Francesco and Savarese, Silvio},
title = {Semantic Cross-View Matching},
year = {2015},
isbn = {9781467397117},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICCVW.2015.137},
doi = {10.1109/ICCVW.2015.137},
abstract = {Matching cross-view images is challenging because the appearance and viewpoints are significantly different. While low-level features based on gradient orientations or filter responses can drastically vary with such changes in viewpoint, semantic information of images however shows an invariant characteristic in this respect. Consequently, semantically labeled regions can be used for performing cross-view matching. In this paper, we therefore explore this idea and propose an automatic method for detecting and representing the semantic information of an RGB image with the goal of performing cross-view matching with a (non-RGB) geographic information system (GIS). A segmented image forms the input to our system with segments assigned to semantic concepts such as traffic signs, lakes, roads, foliage, etc. We design a descriptor to robustly capture both, the presence of semantic concepts and the spatial layout of those segments. Pairwise distances between the descriptors extracted from the GIS map and the query image are then used to generate a shortlist of the most promising locations with similar semantic concepts in a consistent spatial layout. An experimental evaluation with challenging query images and a large urban area shows promising results.},
booktitle = {Proceedings of the 2015 IEEE International Conference on Computer Vision Workshop (ICCVW)},
pages = {1044–1052},
numpages = {9},
series = {ICCVW '15}
}

@InProceedings{regmi2019g2amatching,
author = {Regmi, Krishna and Shah, Mubarak},
title = {Bridging the Domain Gap for Ground-to-Aerial Image Matching},
booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
month = {October},
year = {2019}
}

@INPROCEEDINGS{verma2024globalloco,
  author={Verma, Vandi and Nash, Jeremy and Saldyt, Lucas and Dwight, Quintin and Wang, Haoda and Myint, Steven and Biesiadecki, Jeffrey and Maimone, Mark and Tumbar, Andrei and Ansar, Adnan and Kubiak, Gerik and Hogg, Robert},
  booktitle={2024 IEEE Aerospace Conference},
  title={Enabling Long & Precise Drives for The Perseverance Mars Rover via Onboard Global Localization},
  year={2024},
  volume={},
  number={},
  pages={1-18},
  keywords={Location awareness;Meters;Space vehicles;Earth;Mars;Uncertainty;Navigation},
  doi={10.1109/AERO58975.2024.10521160}}

@InProceedings{ye2025bev,
    author    = {Ye, Junyan and He, Jun and Li, Weijia and Lv, Zhutao and Lin, Yi and Yu, Jinhua and Yang, Haote and He, Conghui},
    title     = {Leveraging BEV Paradigm for Ground-to-Aerial Image Synthesis},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    month     = {October},
    year      = {2025},
    pages     = {28451-28461}
}

@InProceedings{toker2021dte,
    author    = {Toker, Aysim and Zhou, Qunjie and Maximov, Maxim and Leal-Taixe, Laura},
    title     = {Coming Down to Earth: Satellite-to-Street View Synthesis for Geo-Localization},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2021},
    pages     = {6488-6497}
}


@ARTICLE{shi2022geopanoramasynth,
  author={Shi, Yujiao and Campbell, Dylan and Yu, Xin and Li, Hongdong},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  title={Geometry-Guided Street-View Panorama Synthesis From Satellite Imagery},
  year={2022},
  volume={44},
  number={12},
  pages={10009-10022},
  keywords={Satellites;Cameras;Image synthesis;Task analysis;Semantics;Generators;Visualization;Novel view synthesis;satellite imagery;street-view imagery},
  doi={10.1109/TPAMI.2022.3140750}}

@online{Lee2008CentralCylindricalLightProjection,
    author       = {Lee, C. M. G.},
    title        = {Central cylindrical light projection},
    year         = {2008},
    date         = {2008-10-18},
    url          = {https://commons.wikimedia.org/wiki/File:Central_cylindrical_light_projection.svg},
    note         = {SVG image, licensed under CC BY-SA 4.0},
  }

@InProceedings{Rombach_2022_CVPR,
    author    = {Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj\"orn},
    title     = {High-Resolution Image Synthesis With Latent Diffusion Models},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2022},
    pages     = {10684-10695}
}

@INPROCEEDINGS{Szegedy_2016_CVPR,
  author={Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jon and Wojna, Zbigniew},
  booktitle={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  title={Rethinking the Inception Architecture for Computer Vision},
  year={2016},
  volume={},
  number={},
  pages={2818-2826},
  keywords={Convolution;Computer architecture;Training;Computational efficiency;Computer vision;Benchmark testing;Computational modeling},
  doi={10.1109/CVPR.2016.308}}

@inproceedings{
bińkowski2018demystifying,
title={Demystifying {MMD} {GAN}s},
author={Mikołaj Bińkowski and Dougal J. Sutherland and Michael Arbel and Arthur Gretton},
booktitle={International Conference on Learning Representations},
year={2018},
url={https://openreview.net/forum?id=r1lUOzWCW},
}

@inproceedings{
mathieu2016bmse,
title={Deep multi-scale video prediction beyond mean square error},
author={Michael Mathieu and Camille Couprie and Yann LeCun},
booktitle={International Conference on Learning Representations},
year={2016},
url={https://arxiv.org/abs/1511.05440},
}

@ARTICLE{wang2004ssim,
  author={Zhou Wang and Bovik, A.C. and Sheikh, H.R. and Simoncelli, E.P.},
  journal={IEEE Transactions on Image Processing},
  title={Image quality assessment: from error visibility to structural similarity},
  year={2004},
  volume={13},
  number={4},
  pages={600-612},
  keywords={Image quality;Humans;Transform coding;Visual system;Visual perception;Data mining;Layout;Quality assessment;Degradation;Indexes},
  doi={10.1109/TIP.2003.819861}}
